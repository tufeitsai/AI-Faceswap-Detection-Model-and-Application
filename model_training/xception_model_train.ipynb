{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qi_RcEyLKJqk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I3pQ7RInQBa1",
    "outputId": "5e01fc26-248f-4218-e3ed-bf99aaa8bf32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ln7sN3vTkX8M",
    "outputId": "7c29def1-d58a-4d71-9b82-8ba2039f86f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QHJf7JdDkvUp",
    "outputId": "6a3ccb2f-d283-4144-8618-779e136f258d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNVbwOotk1eB",
    "outputId": "f404dea6-c89d-4a3a-f76a-34ea2490b01d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Training set size: 4917\n",
      "Test set size: 1222\n",
      "Epoch 1/10\n",
      "Training Loss: 0.3979\n",
      "Validation Loss: 0.3413, Accuracy: 86.50%\n",
      "Epoch 2/10\n",
      "Training Loss: 0.2988\n",
      "Validation Loss: 0.3150, Accuracy: 88.13%\n",
      "Epoch 3/10\n",
      "Training Loss: 0.2276\n",
      "Validation Loss: 0.2874, Accuracy: 89.53%\n",
      "Epoch 4/10\n",
      "Training Loss: 0.2181\n",
      "Validation Loss: 0.2149, Accuracy: 91.98%\n",
      "Epoch 5/10\n",
      "Training Loss: 0.2076\n",
      "Validation Loss: 1.3883, Accuracy: 67.27%\n",
      "Epoch 6/10\n",
      "Training Loss: 0.2015\n",
      "Validation Loss: 0.5293, Accuracy: 82.41%\n",
      "Epoch 7/10\n",
      "Training Loss: 0.1902\n",
      "Validation Loss: 0.1835, Accuracy: 94.11%\n",
      "Epoch 8/10\n",
      "Training Loss: 0.1720\n",
      "Validation Loss: 0.2235, Accuracy: 91.73%\n",
      "Epoch 9/10\n",
      "Training Loss: 0.1559\n",
      "Validation Loss: 0.4163, Accuracy: 87.56%\n",
      "Epoch 10/10\n",
      "Training Loss: 0.1716\n",
      "Validation Loss: 0.2485, Accuracy: 91.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-260833cc5b13>:171: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model_xcept.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Accuracy: 94.11%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import timm  # PyTorch Image Models库\n",
    "\n",
    "# 检查是否有 GPU 可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# 自定义数据集类，直接读取预处理后的图片\n",
    "class PreprocessedDataset(Dataset):\n",
    "    def __init__(self, image_folder, label, transform=None):\n",
    "        self.image_paths = [\n",
    "            os.path.join(image_folder, img)\n",
    "            for img in os.listdir(image_folder)\n",
    "            if img.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "        ]\n",
    "        self.labels = [label] * len(self.image_paths)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 直接读取预处理后的图片\n",
    "        image = Image.open(self.image_paths[idx]).convert('L')  # 单通道灰度图像\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# 定义数据转换\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(299, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# 定义预处理后图片的保存目录\n",
    "processed_real_train_save_dir = '/content/drive/MyDrive/processed_real_train'\n",
    "processed_real_test_save_dir = '/content/drive/MyDrive/processed_real_test'\n",
    "processed_fake_train_save_dir = '/content/drive/MyDrive/processed_fake_train'\n",
    "processed_fake_test_save_dir = '/content/drive/MyDrive/processed_fake_test'\n",
    "\n",
    "# 加载训练数据集\n",
    "real_train_dataset = PreprocessedDataset(processed_real_train_save_dir, label=0, transform=train_transform)\n",
    "fake_train_dataset = PreprocessedDataset(processed_fake_train_save_dir, label=1, transform=train_transform)\n",
    "train_dataset = ConcatDataset([real_train_dataset, fake_train_dataset])\n",
    "\n",
    "# 加载测试数据集\n",
    "real_test_dataset = PreprocessedDataset(processed_real_test_save_dir, label=0, transform=test_transform)\n",
    "fake_test_dataset = PreprocessedDataset(processed_fake_test_save_dir, label=1, transform=test_transform)\n",
    "test_dataset = ConcatDataset([real_test_dataset, fake_test_dataset])\n",
    "\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# 初始化 Xception 模型\n",
    "def initialize_xception():\n",
    "    model = timm.create_model('xception', pretrained=True)\n",
    "    # 修改第一层卷积层为单通道输入\n",
    "    original_conv1 = model.conv1\n",
    "    model.conv1 = nn.Conv2d(\n",
    "        in_channels=1,\n",
    "        out_channels=original_conv1.out_channels,\n",
    "        kernel_size=original_conv1.kernel_size,\n",
    "        stride=original_conv1.stride,\n",
    "        padding=original_conv1.padding,\n",
    "        bias=original_conv1.bias is not None\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        model.conv1.weight = nn.Parameter(original_conv1.weight.sum(dim=1, keepdim=True))\n",
    "    # 修改最后的全连接层为 2 类输出，并添加 Dropout 层\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(num_ftrs, 2)\n",
    "    )\n",
    "    return model.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = initialize_xception()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# 学习率调度器\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 10\n",
    "best_val_loss = float('inf')\n",
    "early_stop_patience = 5\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    print(f'Training Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    # 在测试集上评估模型\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f'Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    # 学习率调度器步进\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # 早停策略\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        early_stop_counter = 0\n",
    "        # 保存最佳模型权重\n",
    "        torch.save(model.state_dict(), 'best_model_xcept.pth')\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "# 加载最佳模型参数\n",
    "model.load_state_dict(torch.load('best_model_xcept.pth'))\n",
    "\n",
    "# 在测试集上最终评估模型\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'\\nFinal Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APDxgUBkHuDn"
   },
   "outputs": [],
   "source": [
    "# 假设您的模型实例名为 model\n",
    "torch.save(model.state_dict(), '/content/drive/MyDrive/best_model_epoch10_xcept.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZ0t28LwTKTz"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
